{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN-HW3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO/1cKie4YoZZCdOhQZdbPD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AUT-Student/NN-HW3/blob/main/NN_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "slLXpefU8jnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "j5_bZGnS8izB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "f2F3uD7W8KMH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xwyeeLyzCMF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da86d51-1bc2-4e12-a57c-4cf8e6f8675d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
            "To: /content/Dataset.zip\n",
            "100% 61.0M/61.0M [00:01<00:00, 35.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip -O \"/content/Dataset.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/Dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDM9CJlO8vzQ",
        "outputId": "153e9929-5517-4031-a6e6-3fc217b4c980"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Dataset.zip\n",
            "   creating: UCI HAR Dataset/\n",
            "  inflating: UCI HAR Dataset/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/UCI HAR Dataset/\n",
            "  inflating: __MACOSX/UCI HAR Dataset/._.DS_Store  \n",
            "  inflating: UCI HAR Dataset/activity_labels.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/._activity_labels.txt  \n",
            "  inflating: UCI HAR Dataset/features.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/._features.txt  \n",
            "  inflating: UCI HAR Dataset/features_info.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/._features_info.txt  \n",
            "  inflating: UCI HAR Dataset/README.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/._README.txt  \n",
            "   creating: UCI HAR Dataset/test/\n",
            "   creating: UCI HAR Dataset/test/Inertial Signals/\n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/body_acc_x_test.txt  \n",
            "   creating: __MACOSX/UCI HAR Dataset/test/\n",
            "   creating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/\n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_acc_x_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/body_acc_y_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_acc_y_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/body_acc_z_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_acc_z_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/body_gyro_x_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_gyro_x_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/body_gyro_y_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_gyro_y_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/body_gyro_z_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_gyro_z_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/total_acc_x_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._total_acc_x_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/total_acc_y_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._total_acc_y_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/total_acc_z_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._total_acc_z_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/._Inertial Signals  \n",
            "  inflating: UCI HAR Dataset/test/subject_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/._subject_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/X_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/._X_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/y_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/._y_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/._test  \n",
            "   creating: UCI HAR Dataset/train/\n",
            "   creating: UCI HAR Dataset/train/Inertial Signals/\n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/body_acc_x_train.txt  \n",
            "   creating: __MACOSX/UCI HAR Dataset/train/\n",
            "   creating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/\n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_acc_x_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/body_acc_y_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_acc_y_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/body_acc_z_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_acc_z_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/body_gyro_x_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_gyro_x_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/body_gyro_y_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_gyro_y_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/body_gyro_z_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_gyro_z_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/total_acc_x_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._total_acc_x_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/total_acc_y_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._total_acc_y_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/total_acc_z_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._total_acc_z_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/._Inertial Signals  \n",
            "  inflating: UCI HAR Dataset/train/subject_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/._subject_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/X_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/._X_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/y_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/._y_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/._train  \n",
            "  inflating: __MACOSX/._UCI HAR Dataset  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.names -O \"/content/Dataset.names\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7js37rWe8tck",
        "outputId": "69127552-c50d-4c0b-ebd6-fe8d4e146d57"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.names\n",
            "To: /content/Dataset.names\n",
            "\r  0% 0.00/6.30k [00:00<?, ?B/s]\r100% 6.30k/6.30k [00:00<00:00, 10.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat \"/content/Dataset.names\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oINwMqh094xN",
        "outputId": "9d5cb353-f812-47ef-b955-db280d85dd88"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================================================================================================\r\n",
            "Human Activity Recognition Using Smartphones Dataset\r\n",
            "Version 1.0\r\n",
            "===================================================================================================\r\n",
            "Jorge L. Reyes-Ortiz(1,2), Davide Anguita(1), Alessandro Ghio(1), Luca Oneto(1) and Xavier Parra(2)\r\n",
            "1 - Smartlab - Non-Linear Complex Systems Laboratory\r\n",
            "DITEN - Universit�  degli Studi di Genova, Genoa (I-16145), Italy. \r\n",
            "2 - CETpD - Technical Research Centre for Dependency Care and Autonomous Living\r\n",
            "Universitat Polit�cnica de Catalunya (BarcelonaTech). Vilanova i la Geltr� (08800), Spain\r\n",
            "activityrecognition '@' smartlab.ws \r\n",
            "===================================================================================================\r\n",
            "\r\n",
            "The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. \r\n",
            "\r\n",
            "The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details. \r\n",
            "\r\n",
            "For each record it is provided:\r\n",
            "======================================\r\n",
            "\r\n",
            "- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.\r\n",
            "- Triaxial Angular velocity from the gyroscope. \r\n",
            "- A 561-feature vector with time and frequency domain variables. \r\n",
            "- Its activity label. \r\n",
            "- An identifier of the subject who carried out the experiment.\r\n",
            "\r\n",
            "The dataset includes the following files:\r\n",
            "=========================================\r\n",
            "\r\n",
            "- 'README.txt'\r\n",
            "\r\n",
            "- 'features_info.txt': Shows information about the variables used on the feature vector.\r\n",
            "\r\n",
            "- 'features.txt': List of all features.\r\n",
            "\r\n",
            "- 'activity_labels.txt': Links the class labels with their activity name.\r\n",
            "\r\n",
            "- 'train/X_train.txt': Training set.\r\n",
            "\r\n",
            "- 'train/y_train.txt': Training labels.\r\n",
            "\r\n",
            "- 'test/X_test.txt': Test set.\r\n",
            "\r\n",
            "- 'test/y_test.txt': Test labels.\r\n",
            "\r\n",
            "The following files are available for the train and test data. Their descriptions are equivalent. \r\n",
            "\r\n",
            "- 'train/subject_train.txt': Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30. \r\n",
            "\r\n",
            "- 'train/Inertial Signals/total_acc_x_train.txt': The acceleration signal from the smartphone accelerometer X axis in standard gravity units 'g'. Every row shows a 128 element vector. The same description applies for the 'total_acc_x_train.txt' and 'total_acc_z_train.txt' files for the Y and Z axis. \r\n",
            "\r\n",
            "- 'train/Inertial Signals/body_acc_x_train.txt': The body acceleration signal obtained by subtracting the gravity from the total acceleration. \r\n",
            "\r\n",
            "- 'train/Inertial Signals/body_gyro_x_train.txt': The angular velocity vector measured by the gyroscope for each window sample. The units are radians/second. \r\n",
            "\r\n",
            "Notes: \r\n",
            "======\r\n",
            "- Features are normalized and bounded within [-1,1].\r\n",
            "- Each feature vector is a row on the text file.\r\n",
            "- The units used for the accelerations (total and body) are 'g's (gravity of earth -> 9.80665 m/seg2).\r\n",
            "- The gyroscope units are rad/seg.\r\n",
            "- A video of the experiment including an example of the 6 recorded activities with one of the participants can be seen in the following link: http://www.youtube.com/watch?v=XOEN9W05_4A\r\n",
            "\r\n",
            "For more information about this dataset please contact: activityrecognition '@' smartlab.ws\r\n",
            "\r\n",
            "License:\r\n",
            "========\r\n",
            "Use of this dataset in publications must be acknowledged by referencing the following publication [1] \r\n",
            "\r\n",
            "[1] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013. \r\n",
            "\r\n",
            "This dataset is distributed AS-IS and no responsibility implied or explicit can be addressed to the authors or their institutions for its use or misuse. Any commercial use is prohibited.\r\n",
            "\r\n",
            "Other Related Publications:\r\n",
            "===========================\r\n",
            "[2] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge L. Reyes-Ortiz.  Energy Efficient Smartphone-Based Activity Recognition using Fixed-Point Arithmetic. Journal of Universal Computer Science. Special Issue in Ambient Assisted Living: Home Care.   Volume 19, Issue 9. May 2013\r\n",
            "\r\n",
            "[3] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. 4th International Workshop of Ambient Assited Living, IWAAL 2012, Vitoria-Gasteiz, Spain, December 3-5, 2012. Proceedings. Lecture Notes in Computer Science 2012, pp 216-223. \r\n",
            "\r\n",
            "[4] Jorge Luis Reyes-Ortiz, Alessandro Ghio, Xavier Parra-Llanas, Davide Anguita, Joan Cabestany, Andreu Catal�. Human Activity and Motion Disorder Recognition: Towards Smarter Interactive Cognitive Environments. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.  \r\n",
            "\r\n",
            "==================================================================================================\r\n",
            "Jorge L. Reyes-Ortiz, Alessandro Ghio, Luca Oneto, Davide Anguita and Xavier Parra. November 2013.\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat \"/content/UCI HAR Dataset/activity_labels.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlHR2zgU-Yk3",
        "outputId": "a56d6a7c-586d-4276-ab4e-61d94fcf9271"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 WALKING\n",
            "2 WALKING_UPSTAIRS\n",
            "3 WALKING_DOWNSTAIRS\n",
            "4 SITTING\n",
            "5 STANDING\n",
            "6 LAYING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.read_csv(\"/content/UCI HAR Dataset/train/X_train.txt\", delimiter=r\"\\s+\", header=None)\n",
        "X_test = pd.read_csv(\"/content/UCI HAR Dataset/test/X_test.txt\", delimiter=r\"\\s+\", header=None)\n",
        "y_train = pd.read_csv(\"/content/UCI HAR Dataset/train/y_train.txt\", delimiter=r\"\\s+\", header=None)\n",
        "y_test = pd.read_csv(\"/content/UCI HAR Dataset/test/y_test.txt\", delimiter=r\"\\s+\", header=None)"
      ],
      "metadata": {
        "id": "V3JPy5L5qgHW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[\"Class\"] = y_train\n",
        "X_test[\"Class\"] = y_test"
      ],
      "metadata": {
        "id": "ehah1xhWFG1E"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_train = np.split(X_train.sample(frac=1, random_state=0), [int(.125*len(X_train))])"
      ],
      "metadata": {
        "id": "eFqW_pxw_2Yk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = X_train[\"Class\"]\n",
        "X_train = X_train.drop(columns=[\"Class\"])\n",
        "\n",
        "y_valid = X_valid[\"Class\"]\n",
        "X_valid = X_valid.drop(columns=[\"Class\"])"
      ],
      "metadata": {
        "id": "pGez1UEkH119"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.apply(lambda x:x-1)\n",
        "y_test = y_test.apply(lambda x:x-1)\n",
        "y_valid = y_valid.apply(lambda x:x-1)"
      ],
      "metadata": {
        "id": "6pUkZ-WvQxoB"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Classifer"
      ],
      "metadata": {
        "id": "CdO_O8ws5wPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPModel(keras.Model):\n",
        "  def __init__(self, number_hidden_layers, number_hidden_units):\n",
        "    super().__init__()\n",
        "\n",
        "    if number_hidden_layers<0:\n",
        "      raise Exception(\"The number of hidden layers must be a non-negetive number\")\n",
        "\n",
        "    if number_hidden_layers != len(number_hidden_units):\n",
        "      raise Exception(\"The number of hidden layers must equal to the length of the number of hidden units list\")\n",
        "\n",
        "    self.model = keras.models.Sequential()\n",
        "\n",
        "    for i in range(number_hidden_layers):\n",
        "      self.model.add(keras.layers.Dense(units=number_hidden_units[i], activation=\"relu\", name=f\"Dense_Layer_{i+1}\"))\n",
        "\n",
        "    self.model.add(keras.layers.Dense(6, activation=\"softmax\", name=\"Output_Layer\"))\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self.model(inputs)"
      ],
      "metadata": {
        "id": "MrD12o6V2KpU"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(number_hidden_layers, number_hidden_units, learning_rate):\n",
        "  es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", restore_best_weights=True, patience=5)\n",
        "\n",
        "  model = MLPModel(number_hidden_layers=number_hidden_layers, number_hidden_units=number_hidden_units)\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  \n",
        "  model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  model.fit(x=X_train, y=y_train, epochs=30, validation_data=(X_valid, y_valid), verbose=0, callbacks=[es_callback])\n",
        "\n",
        "  train_accuracy = model.evaluate(X_train, y_train, verbose=0)[1]\n",
        "  validation_accuracy = model.evaluate(X_valid, y_valid, verbose=0)[1]\n",
        "\n",
        "  print(f\"Train = {round(train_accuracy*100, 2)}, Validation = {round(validation_accuracy*100, 2)}\")"
      ],
      "metadata": {
        "id": "FEgCM9BW7kat"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Rate Fine-tuning"
      ],
      "metadata": {
        "id": "HJpVmTbPlUOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for learning_rate in [0.0001, 0.0005, 0.001, 0.003, 0.005, 0.01, 0.1]:\n",
        "  print(f\"Learning Rate = {learning_rate}\")\n",
        "  train_and_evaluate(number_hidden_layers=3, number_hidden_units=[128, 64, 32], learning_rate=0.001)\n",
        "  print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5OGkKLNifjj",
        "outputId": "a8f46aad-d80b-45df-e932-f1f6dacd3e41"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate = 0.0001\n",
            "Train = 98.83, Validation = 97.71\n",
            "\n",
            "Learning Rate = 0.0005\n",
            "Train = 98.85, Validation = 97.82\n",
            "\n",
            "Learning Rate = 0.001\n",
            "Train = 97.95, Validation = 96.52\n",
            "\n",
            "Learning Rate = 0.003\n",
            "Train = 98.8, Validation = 98.04\n",
            "\n",
            "Learning Rate = 0.005\n",
            "Train = 98.4, Validation = 97.17\n",
            "\n",
            "Learning Rate = 0.01\n",
            "Train = 98.77, Validation = 97.93\n",
            "\n",
            "Learning Rate = 0.1\n",
            "Train = 98.57, Validation = 97.93\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Number Layer and Number Neuron Fine-tuning"
      ],
      "metadata": {
        "id": "AW_-4dPPlZf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate(number_hidden_layers=0, number_hidden_units=[], learning_rate=0.003)\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNEc3An_i0uz",
        "outputId": "aadfe69a-f222-46cf-da5f-64a3b0a0af13"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train = 98.82, Validation = 97.93\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for number_hidden_units in [[32], [64], [128]]:\n",
        "  print(f\"number_hidden_units = {number_hidden_units}\")\n",
        "  train_and_evaluate(number_hidden_layers=1, number_hidden_units=number_hidden_units, learning_rate=0.003)\n",
        "  print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySIXtRVvlR01",
        "outputId": "3a002eb4-411c-4dec-b507-2f4b440859a1"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number_hidden_units = [32]\n",
            "Train = 98.96, Validation = 97.93\n",
            "\n",
            "number_hidden_units = [64]\n",
            "Train = 98.87, Validation = 97.82\n",
            "\n",
            "number_hidden_units = [128]\n",
            "Train = 98.87, Validation = 98.04\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for number_hidden_units in [\n",
        "                            [32, 32], [64, 32], [128, 128]\n",
        "                            ]:\n",
        "  print(f\"number_hidden_units = {number_hidden_units}\")\n",
        "  train_and_evaluate(number_hidden_layers=2, number_hidden_units=number_hidden_units, learning_rate=0.003)\n",
        "  print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoDRMe3-l79A",
        "outputId": "17de5942-3702-42da-c709-e5c88edd04ad"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number_hidden_units = [32, 32]\n",
            "Train = 98.87, Validation = 98.26\n",
            "\n",
            "number_hidden_units = [64, 32]\n",
            "Train = 98.4, Validation = 97.06\n",
            "\n",
            "number_hidden_units = [128, 128]\n",
            "Train = 97.28, Validation = 96.63\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for number_hidden_units in [\n",
        "                            [64, 32, 32], [64, 64, 64], [128, 64, 32]\n",
        "                            ]:\n",
        "  print(f\"number_hidden_units = {number_hidden_units}\")\n",
        "  train_and_evaluate(number_hidden_layers=3, number_hidden_units=number_hidden_units, learning_rate=0.003)\n",
        "  print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg4yKaXemQJu",
        "outputId": "90586100-816b-435d-b9bb-ef90f3136c95"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number_hidden_units = [64, 32, 32]\n",
            "Train = 98.49, Validation = 97.71\n",
            "\n",
            "number_hidden_units = [64, 64, 64]\n",
            "Train = 98.15, Validation = 97.39\n",
            "\n",
            "number_hidden_units = [128, 64, 32]\n",
            "Train = 98.26, Validation = 97.28\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for number_hidden_units in [\n",
        "                            [128, 128, 64, 64], [128, 64, 32, 16], [128, 64, 32, 64]\n",
        "                            ]:\n",
        "  print(f\"number_hidden_units = {number_hidden_units}\")\n",
        "  train_and_evaluate(number_hidden_layers=4, number_hidden_units=number_hidden_units, learning_rate=0.05)\n",
        "  print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cRFD9AFmaDH",
        "outputId": "347173c5-6496-488e-d248-97b970f34093"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number_hidden_units = [128, 128, 64, 64]\n",
            "Train = 18.76, Validation = 18.17\n",
            "\n",
            "number_hidden_units = [128, 64, 32, 16]\n",
            "Train = 52.45, Validation = 50.82\n",
            "\n",
            "number_hidden_units = [128, 64, 32, 64]\n",
            "Train = 18.76, Validation = 18.17\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4xW0sGOGn85x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}